{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-core in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (1.29.3)\n",
      "Requirement already satisfied: requests>=2.18.4 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from azure-core) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from azure-core) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from azure-core) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from requests>=2.18.4->azure-core) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from requests>=2.18.4->azure-core) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from requests>=2.18.4->azure-core) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from requests>=2.18.4->azure-core) (2023.7.22)\n",
      "Requirement already satisfied: openai in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (0.27.9)\n",
      "Requirement already satisfied: requests>=2.20 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Collecting azure-search-documents\n",
      "  Obtaining dependency information for azure-search-documents from https://files.pythonhosted.org/packages/25/f4/ec7c1d6bafb037d3017db93ef44e18efe84e6d4e7b8906153a9bb777786e/azure_search_documents-11.4.0b8-py3-none-any.whl.metadata\n",
      "  Using cached azure_search_documents-11.4.0b8-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.24.0 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from azure-search-documents) (1.29.3)\n",
      "Requirement already satisfied: azure-common~=1.1 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from azure-search-documents) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from azure-search-documents) (0.6.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents) (2023.7.22)\n",
      "Using cached azure_search_documents-11.4.0b8-py3-none-any.whl (305 kB)\n",
      "Installing collected packages: azure-search-documents\n",
      "Successfully installed azure-search-documents-11.4.0b8\n",
      "Requirement already satisfied: PyPDF2 in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: tenacity in e:\\ai\\ws-azure-openai-intro\\.venv\\lib\\site-packages (8.2.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install azure-core\n",
    "! pip install openai\n",
    "! pip install azure-search-documents --pre\n",
    "! pip install PyPDF2\n",
    "! pip install tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: azure-search-documents 11.4.0b8\n",
      "Uninstalling azure-search-documents-11.4.0b8:\n",
      "  Successfully uninstalled azure-search-documents-11.4.0b8\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall azure-search-documents -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import PyPDF2\n",
    "import fnmatch\n",
    "from dotenv import load_dotenv\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import SearchIndex\n",
    "from azure.search.documents.models import Vector\n",
    "from azure.search.documents.indexes.models import (\n",
    "    ComplexField,\n",
    "    CorsOptions,\n",
    "    SearchIndex,\n",
    "    SemanticConfiguration,\n",
    "    PrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSettings,\n",
    "    VectorSearch,\n",
    "    HnswVectorSearchAlgorithmConfiguration,\n",
    "    ScoringProfile,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key: 1c7f2...3613f\n",
      "OpenAI API base: https://wsl-openai-canada.openai.azure.com/\n",
      "OpenAI API version: 2023-03-15-preview\n",
      "OpenAI API type: azure\n",
      "Azure Search service name: wsl-cog-search-test-2\n",
      "Azure Search service key: 9GUM9...z1hrb\n",
      "Azure Search index name: cogsrch-index\n",
      "Azure Search endpoint: https://wsl-cog-search-test-2.search.windows.net/\n",
      "Data directory: E:/AI/PDFs/Colbun/\n",
      "Index schema: ./index_schema.json\n"
     ]
    }
   ],
   "source": [
    "# Load secrets and config from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API\n",
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "embedding_model = os.getenv(\"OPENAI_EMBEDDING_MODEL\")\n",
    "print(\"OpenAI API key: {}\".format(openai.api_key[:5] + '...' + openai.api_key[-5:]))\n",
    "print(\"OpenAI API base: {}\".format(openai.api_base))\n",
    "print(\"OpenAI API version: {}\".format(openai.api_version))\n",
    "print(\"OpenAI API type: {}\".format(openai.api_type))\n",
    "\n",
    "# Azure Search API\n",
    "search_service_name = os.getenv(\"SEARCH_SERVICE_NAME\")\n",
    "search_service_key = os.getenv(\"SEARCH_SERVICE_KEY\")\n",
    "search_index_name = os.getenv(\"SEARCH_INDEX_NAME\")\n",
    "search_endpoint = \"https://{}.search.windows.net/\".format(search_service_name)\n",
    "print(\"Azure Search service name: {}\".format(search_service_name))\n",
    "print(\"Azure Search service key: {}\".format(search_service_key[:5] + '...' + search_service_key[-5:]))\n",
    "print(\"Azure Search index name: {}\".format(search_index_name))\n",
    "print(\"Azure Search endpoint: {}\".format(search_endpoint))\n",
    "\n",
    "# Other variables\n",
    "data_directory = os.getenv(\"FILEPATH_TO_DATA\")\n",
    "index_schema = os.getenv(\"FILEPATH_TO_INDEX_SCHEMA\")\n",
    "print(\"Data directory: {}\".format(data_directory))\n",
    "print(\"Index schema: {}\".format(index_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a client\n",
    "class CreateClient(object):\n",
    "    def __init__(self, endpoint, key, index_name):\n",
    "        self.endpoint = endpoint\n",
    "        self.index_name = index_name\n",
    "        self.key = key\n",
    "        self.credentials = AzureKeyCredential(key)\n",
    "\n",
    "    # Create a SearchClient\n",
    "    # Use this to upload docs to the Index\n",
    "    def create_search_client(self):\n",
    "        return SearchClient(\n",
    "            endpoint=self.endpoint,\n",
    "            index_name=self.index_name,\n",
    "            credential=self.credentials,\n",
    "        )\n",
    "\n",
    "    # Create a SearchIndexClient\n",
    "    # This is used to create, manage, and delete an index\n",
    "    def create_admin_client(self):\n",
    "        return SearchIndexClient(endpoint=self.endpoint, credential=self.credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Search Index from the schema\n",
    "# If reading the schema from a URL, set url=True\n",
    "def create_schema_from_json_and_upload(schema, index_name, admin_client):\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(schema):\n",
    "        raise ValueError(f\"Schema file '{schema}' does not exist\")\n",
    "    \n",
    "    # Open the file and load the schema data\n",
    "    with open(schema) as json_file:\n",
    "        schema_data = json.load(json_file)\n",
    "    \n",
    "    cors_options = CorsOptions(allowed_origins=[\"*\"], max_age_in_seconds=60)\n",
    "    scoring_profiles = []\n",
    "\n",
    "    index = SearchIndex(\n",
    "        name=index_name,\n",
    "        fields=schema_data[\"fields\"],\n",
    "        scoring_profiles=scoring_profiles,\n",
    "        suggesters=schema_data[\"suggesters\"],\n",
    "        cors_options=cors_options,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        upload_schema = admin_client.create_index(index)\n",
    "        if upload_schema:\n",
    "            print(f\"Schema uploaded; Index created for {index_name}.\")\n",
    "        else:\n",
    "            exit(0)\n",
    "    except:\n",
    "        print(\"Unexpected error:\", sys.exc_info()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(5))\n",
    "def generate_embeddings(text):\n",
    "    response = openai.Embedding.create(input=text, engine=embedding_model)\n",
    "    embeddings = response[\"data\"][0]['embedding']\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date_to_iso8601(date):\n",
    "    try:\n",
    "        date = date.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    except:\n",
    "        print(\"Error converting date to ISO8601 format\")\n",
    "        date = None\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdfs_and_upload_to_index(root_dir, client):\n",
    "    data_list = []\n",
    "    id_count = 1\n",
    "    total_files = sum(len(files) for _, _, files in os.walk(root_dir))\n",
    "    count = 0\n",
    "    \n",
    "    for dirpath, dirs, files in os.walk(root_dir):\n",
    "        for filename in fnmatch.filter(files, '*.pdf'):\n",
    "            count += 1\n",
    "            print(f\"Processing {filename} {count}/{total_files}\")\n",
    "            pdf_file = os.path.join(dirpath, filename)\n",
    "            \n",
    "            with open(pdf_file, 'rb') as fileobj:\n",
    "                pdf = PyPDF2.PdfReader(fileobj)\n",
    "                info = pdf.metadata\n",
    "                author = info.author\n",
    "                created_date = info.creation_date\n",
    "                mod_date = info.modification_date\n",
    "                num_pages = len(pdf.pages)\n",
    "\n",
    "                # loop through each page of the PDF\n",
    "                for i in range(num_pages):\n",
    "                    text = pdf.pages[i].extract_text()\n",
    "                    \n",
    "                    try:\n",
    "                        embeddings = generate_embeddings(text)\n",
    "                    except:\n",
    "                        print(f\"Error generating embeddings for {pdf_file}\")\n",
    "                        continue\n",
    "\n",
    "                    data = {\n",
    "                        \"id\": str(id_count),\n",
    "                        \"filename\": os.path.basename(pdf_file),\n",
    "                        \"author\": author,\n",
    "                        \"page_number\": i+1,\n",
    "                        \"total_pages\": num_pages,\n",
    "                        \"content\": text,\n",
    "                        \"embeddings\": embeddings\n",
    "                    }\n",
    "                    \n",
    "                    data[\"created_date\"] = convert_date_to_iso8601(created_date)\n",
    "                    if not data[\"created_date\"]:\n",
    "                        continue\n",
    "                    \n",
    "                    data[\"last_modified_date\"] = convert_date_to_iso8601(mod_date)\n",
    "                    if not data[\"last_modified_date\"]:\n",
    "                        continue\n",
    "\n",
    "                    data_list.append(data)\n",
    "                    id_count += 1\n",
    "                \n",
    "    client.upload_documents(documents=data_list)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema uploaded; Index created for cogsrch-index.\n",
      "Processing DE03587-23.pdf 1/100\n",
      "Processing DE03590-23.pdf 2/100\n",
      "Processing DE03591-23.pdf 3/100\n",
      "Processing DE03592-23.pdf 4/100\n",
      "Processing DE03596-23.pdf 5/100\n",
      "Processing DE03597-23.pdf 6/100\n",
      "Processing DE03598-23.pdf 7/100\n",
      "Processing DE03599-23.pdf 8/100\n",
      "Processing DE03610-23.pdf 9/100\n",
      "Processing DE03612-23.pdf 10/100\n",
      "Processing DE03613-23.pdf 11/100\n",
      "Error converting created_date for E:/AI/PDFs/Colbun/DE03613-23.pdf\n",
      "Error converting created_date for E:/AI/PDFs/Colbun/DE03613-23.pdf\n",
      "Processing DE03616-23.pdf 12/100\n",
      "Processing DE03617-23.pdf 13/100\n",
      "Processing DE03634-23.pdf 14/100\n",
      "Processing DE03641-23.pdf 15/100\n",
      "Processing DE03642-23.pdf 16/100\n",
      "Processing DE03643-23.pdf 17/100\n",
      "Processing DE03644-23.pdf 18/100\n",
      "Processing DE03646-23.pdf 19/100\n",
      "Processing DE03647-23.pdf 20/100\n",
      "Processing DE03655-23.pdf 21/100\n",
      "Processing DE03661-23.pdf 22/100\n",
      "Processing DE03663-23.pdf 23/100\n",
      "Processing DE03664-23.pdf 24/100\n",
      "Error converting created_date for E:/AI/PDFs/Colbun/DE03664-23.pdf\n",
      "Error converting created_date for E:/AI/PDFs/Colbun/DE03664-23.pdf\n",
      "Processing DE03665-23.pdf 25/100\n",
      "Error converting created_date for E:/AI/PDFs/Colbun/DE03665-23.pdf\n",
      "Error converting created_date for E:/AI/PDFs/Colbun/DE03665-23.pdf\n",
      "Processing DE03672-23.pdf 26/100\n",
      "Processing DE03676-23.pdf 27/100\n",
      "Processing DE03684-23.pdf 28/100\n",
      "Processing DE03690-23.pdf 29/100\n",
      "Processing DE03692-23.pdf 30/100\n",
      "Processing DE03699-23.pdf 31/100\n",
      "Processing DE03702-23.pdf 32/100\n",
      "Processing DE03707-23.pdf 33/100\n",
      "Processing DE03708-23.pdf 34/100\n",
      "Processing DE03715-23.pdf 35/100\n",
      "Processing DE03716-23.pdf 36/100\n",
      "Processing DE03717-23.pdf 37/100\n",
      "Processing DE03722-23.pdf 38/100\n",
      "Processing DE03725-23.pdf 39/100\n",
      "Processing DE03731-23.pdf 40/100\n",
      "Processing DE03733-23.pdf 41/100\n",
      "Processing DE03734-23.pdf 42/100\n",
      "Processing DE03738-23.pdf 43/100\n",
      "Processing DE03739-23.pdf 44/100\n",
      "Processing DE03740-23.pdf 45/100\n",
      "Processing DE03741-23.pdf 46/100\n",
      "Processing DE03742-23.pdf 47/100\n",
      "Processing DE03743-23.pdf 48/100\n",
      "Processing DE03746-23.pdf 49/100\n",
      "Processing DE03759-23.pdf 50/100\n",
      "Processing DE03767-23.pdf 51/100\n",
      "Processing DE03768-23.pdf 52/100\n",
      "Processing DE03770-23.pdf 53/100\n",
      "Processing DE03772-23.pdf 54/100\n",
      "Processing DE03774-23.pdf 55/100\n",
      "Processing DE03776-23.pdf 56/100\n",
      "Processing DE03777-23.pdf 57/100\n",
      "Processing DE03785-23.pdf 58/100\n",
      "Processing DE03793-23.pdf 59/100\n",
      "Processing DE03794-23.pdf 60/100\n",
      "Processing DE03797-23.pdf 61/100\n",
      "Processing DE03798-23.pdf 62/100\n",
      "Processing DE03799-23.pdf 63/100\n",
      "Processing DE03800-23.pdf 64/100\n",
      "Processing DE03817-23.pdf 65/100\n",
      "Error converting last_modified_date for E:/AI/PDFs/Colbun/DE03817-23.pdf\n",
      "Error converting last_modified_date for E:/AI/PDFs/Colbun/DE03817-23.pdf\n",
      "Processing DE03819-23.pdf 66/100\n",
      "Processing DE03820-23.pdf 67/100\n",
      "Processing DE03826-23.pdf 68/100\n",
      "Processing DE03829-23.pdf 69/100\n",
      "Processing DE03834-23.pdf 70/100\n",
      "Processing DE03839-23.pdf 71/100\n",
      "Processing DE03840-23.pdf 72/100\n",
      "Error converting created_date for E:/AI/PDFs/Colbun/DE03840-23.pdf\n",
      "Processing DE03846-23.pdf 73/100\n",
      "Processing DE03847-23.pdf 74/100\n",
      "Processing DE03851-23.pdf 75/100\n",
      "Processing DE03856-23.pdf 76/100\n",
      "Error converting created_date for E:/AI/PDFs/Colbun/DE03856-23.pdf\n",
      "Error converting created_date for E:/AI/PDFs/Colbun/DE03856-23.pdf\n",
      "Processing DE03857-23.pdf 77/100\n",
      "Error converting created_date for E:/AI/PDFs/Colbun/DE03857-23.pdf\n",
      "Error converting created_date for E:/AI/PDFs/Colbun/DE03857-23.pdf\n",
      "Processing DE03861-23.pdf 78/100\n",
      "Error converting created_date for E:/AI/PDFs/Colbun/DE03861-23.pdf\n",
      "Error converting created_date for E:/AI/PDFs/Colbun/DE03861-23.pdf\n",
      "Processing DE03874-23.pdf 79/100\n",
      "Error converting created_date for E:/AI/PDFs/Colbun/DE03874-23.pdf\n",
      "Processing DE04510-23.pdf 80/100\n",
      "Processing DE04524-23.pdf 81/100\n",
      "Processing DE04567-23.pdf 82/100\n",
      "Processing DE04635-23.pdf 83/100\n",
      "Processing DE04710-23.pdf 84/100\n",
      "Processing DE04762-23.pdf 85/100\n",
      "Processing DE04864-23.pdf 86/100\n",
      "Processing DE04865-23.pdf 87/100\n",
      "Processing DE04866-23.pdf 88/100\n",
      "Processing DE04903-23.pdf 89/100\n",
      "Processing DE04904-23.pdf 90/100\n",
      "Processing DE04974-23.pdf 91/100\n",
      "Processing DE04985-23.pdf 92/100\n",
      "Processing DE05045-23.pdf 93/100\n",
      "Processing DE05054-23.pdf 94/100\n",
      "Processing DE05092-23.pdf 95/100\n",
      "Processing DE05097-23.pdf 96/100\n",
      "Processing DE05117-23.pdf 97/100\n",
      "Processing DE05136-23.pdf 98/100\n",
      "Processing DE05139-23.pdf 99/100\n",
      "Processing DE05143-23.pdf 100/100\n",
      "Done!\n",
      "Upload complete\n"
     ]
    }
   ],
   "source": [
    "schema = create_schema_from_json_and_upload(index_schema, search_index_name, admin_client)\n",
    "convert_pdfs_and_upload_to_index(data_directory, search_client)\n",
    "print(\"Upload complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index deleted\n"
     ]
    }
   ],
   "source": [
    "# Clean up Azure resources\n",
    "admin_client.delete_index(search_index_name)\n",
    "print(\"Index deleted\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
